# -*- coding: utf-8 -*-
"""Medical_insurance_predictions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZA6jD_KC-3twUihcrKI347FzIHx0iv0r
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from prettytable import PrettyTable
# %matplotlib inline

#loading data file in csv format and displaying it
df=pd.read_csv('/content/drive/MyDrive/insurance.csv')

# displaying the file
df.head()

# no.of rows and columns
df.shape

#information about the dataset
df.info()

"""Categorical Features:


1.   sex
2.   smoker
3.   region


Numerical features:


1.  age 
2.  bmi 
3.  children









"""

#checking for null values
df.isnull().sum()

"""There are no missing values in the dataset

**DATA ANALYSIS**
"""

#statistical summary of the data
df.describe()

#distribution of age value

sns.set()
plt.figure(figsize = (6,6))
sns.distplot(df['age'])
plt.title('Age Distribution')
plt.show()

sns.displot(data = df,  x = 'age', hue = 'region', kind = 'kde')
plt.title('Distribution of Ages in different Regions', fontsize = 15)

plt.show()

"""Distribution of age is similar in all regions"""

#distribution of bmi values

sns.set()
plt.figure(figsize = (6,6))
sns.distplot(df['bmi'])
plt.title('BMI Distribution')
plt.show()

"""1. As we know, Normal BMI range is 18.5 to 24.9.
2. Most of the people in this dataset are overweight.
"""

#distribution of bmi across genders

sns.displot(data = df, x = 'bmi', hue = 'sex', kind = 'kde')

"""Males tend to be more overweight than females"""

#gender column

plt.figure(figsize = (6,6))

sns.countplot(data = df, x = 'sex')
plt.title('Sex Distribution')
plt.show()

#counts of male and female in dataset
df['sex'].value_counts()

#children column

plt.figure(figsize = (6,6))
sns.countplot(data = df, x = 'children')

plt.title('Children Distribution')
plt.show()

"""Majority of the people have 0 children"""

#% of people having children

(df['children'].value_counts()/df.shape[0])*100

"""42% of people dont have children."""

#smoker column

plt.figure(figsize = (6,6))
sns.countplot(data = df, x = 'smoker')

plt.title('Smoker Distribution')
plt.show()

"""Majority of the people are non smokers"""

df['smoker'].value_counts()

#region column

plt.figure(figsize = (6,6))
sns.countplot(data = df, x = 'region')

plt.title('Region Distribution')
plt.show()

df['region'].value_counts()

#distribution of charges

plt.figure(figsize = (6,6))
sns.displot(data = df, x = 'charges',hue = 'sex', kind = 'kde')
plt.title('Charges Distribution')
plt.show()

"""Both males and females have almost similar distributions"""

plt.figure(figsize = (10,6))
sns.displot(data = df,  x = 'charges', hue = 'smoker', kind = 'kde')
plt.title('Variation of Charges with BMI if he/she is smoker', fontsize = 20)

plt.show()

"""Usually non smokers have to pay less charges than smokers"""

plt.figure(figsize = (10,6))
sns.scatterplot(data = df, x = 'bmi', y = 'charges', hue = 'sex')
plt.title('Variation of Charges with BMI in different Gender', fontsize = 20)

plt.show()

"""1. Majority of the people have charges less than 30000.
2. People paying high charges have a greater bmi.
3. Most have a bmi within 35
4. The person paying the highest charge has a very high bmi.
"""

plt.figure(figsize = (10,6))
sns.scatterplot(data = df, x = 'bmi', y = 'charges', hue = 'smoker')
plt.title('Variation of Charges with BMI if he/she is smoker', fontsize = 20)

plt.show()

"""1. Here we seem to have positive correlation between BMI and Charges. 
2. Persons who are smoker have to pay more charges than non-smoker.
"""

sns.heatmap(df.corr(),  annot = True)
plt.title('Correlation Coefficients', fontsize = 20)
plt.show()

plt.figure(figsize = (10,6))
sns.scatterplot(data = df, x = 'age', y = 'charges')
plt.title('Variation of Charges with Age', fontsize = 20)

plt.show()

"""1. Charges seem to increase with age."""

sns.displot(data = df,  x = 'charges', hue = 'region', kind = 'kde')
plt.title('Distribution of Charges in different Regions', fontsize = 15)

plt.show()

"""1. In all regions, distribution is similar.

2. Although SouthEast has more proportion of people paying higher    charges than in other regions.
"""

sns.barplot(data = df, x = 'region', y = 'charges', hue = 'smoker')

plt.title('Barplot Showing Mean Charges in Different Regions on the basis of Smoking Behaviour', fontsize = 15)
plt.legend(ncol=2, loc="upper right", frameon=True)
plt.show

sns.displot(data = df,  x = 'bmi', hue = 'region',kind='kde')
plt.title('Distribution of bmi in different Regions', fontsize = 15)

plt.show()

"""1.   Southeast region tends to have a higher bmi than other regions.
2.   Northwest region has the lowest bmi of all regions.

**DATA PREPROCESSING**

**ENCODING THE CATEGORICAL FEATURES**
"""

#categorical features
cat_features = ['sex', 'smoker', 'region']

#it'll by default convert object datatype to dummies, and all object data type features are categorical features
data_encoded = pd.get_dummies(df, drop_first = True)

data_encoded.head()

"""**SPLITTING DATA INTO TRAINING AND TESTING DATA**"""

#taking features required to train the model and removing target feature
X = data_encoded.drop('charges', axis = 1)

y = data_encoded['charges']

#split train and test into 80 - 20 split and keeping randon_state to get repeated results 
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

print('Shape of train data X and y respectively : ', x_train.shape, ':', y_train.shape)
print('Shape of test data X and y respectively : ', x_test.shape, ':', y_test.shape)

"""**MODELS**"""

def best_hyp_finder_gridsearchcv(train_x, train_y, params, model, scoring = 'neg_root_mean_squared_error', cv = 3):
    
    
    #defining gridserachcv technique with decisiontree classifier model
    reg = GridSearchCV(model, param_grid = params, scoring = scoring, cv = cv, return_train_score = True)
    reg.fit(train_x, y_train)

    results = pd.DataFrame(reg.cv_results_)
    best_params = reg.best_params_
    
    print('Best Hyper Parameters are :', best_params)
    
    return results, best_params

"""**LINEAR REGRESSION**"""

#MODEL TRAINING
lr = LinearRegression()

lr.fit(x_train, y_train)

"""PREDICTION"""

#prediction on for train and test data

train_predict_lr = lr.predict(x_train)

test_predict_lr  = lr.predict(x_test)

"""MODEL EVALUATION"""

# compute R2 value for checking performance of model on training and test data

r2_train_lr = metrics.r2_score(y_train, train_predict_lr)

print('R2 score on train data :',r2_train_lr)

r2_test_lr = metrics.r2_score(y_test, test_predict_lr)

print('R2 score on test data :',r2_test_lr)

#rmse 

rmse_train_lr = metrics.mean_squared_error(y_train, train_predict_lr, squared = False)

print('Root mean squared error on train data :',rmse_train_lr)


rmse_test_lr = metrics.mean_squared_error(y_test, test_predict_lr, squared = False)

print('Root mean squared error on test data :',rmse_test_lr)

"""Plotting a graph"""

fig, (ax1) = plt.subplots(1, figsize=(12,6))

ax1.scatter(test_predict_lr, y_test, s=20)
ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
ax1.set_ylabel("True")
ax1.set_xlabel("Predicted")
ax1.set_title("Linear Regression")

"""**SUPPORT VECTOR REGRESSOR**

MODEL TRAINING
"""

svr = SVR(kernel = 'rbf')

# svr.fit(x_train, y_train)

"""HYPER PARAMETER TUNING"""

parameters = {'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],'C': [1, 10, 100, 1000, 10000]}

results_svr, best_params_svr = best_hyp_finder_gridsearchcv(x_train, y_train, params = parameters, model = svr, scoring = 'neg_root_mean_squared_error',cv=3)

"""Model training using best parameters"""

svr = SVR(kernel = 'rbf', C = best_params_svr['C'], gamma = best_params_svr['gamma'])

svr.fit(x_train, y_train)

#prediction for train and test data

y_tr_pred_svr = svr.predict(x_train)

y_te_pred_svr = svr.predict(x_test)

"""Model evaluation"""

# compute R2 value for checking performance of model on training and test data

r2_train_svr = metrics.r2_score(y_train, y_tr_pred_svr)
r2_test_svr = metrics.r2_score(y_test, y_te_pred_svr)

rmse_train_svr = metrics.mean_squared_error(y_train, y_tr_pred_svr, squared = False)
rmse_test_svr = metrics.mean_squared_error(y_test, y_te_pred_svr, squared = False)

print('R2 score on train data :',r2_train_svr)
print('R2 score on test data :',r2_test_svr)
print('Root mean squared error on train data :',rmse_train_svr)
print('Root mean squared error on test data :',rmse_test_svr)

"""Plotting a graph"""

fig, (ax1) = plt.subplots(1, figsize=(12,6))
plt.scatter(y_test, y_te_pred_svr)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Support Vector Regressor")
plt.show()

"""**RANDOM FOREST REGRESSOR**"""

#creating instance of RandomForestRegressor
rfr = RandomForestRegressor()

parameters = {'n_estimators' : [10, 50, 100, 150, 200, 300, 500, 1000], 'max_depth' : range(2,11)}

results_rfr, best_params_rfr = best_hyp_finder_gridsearchcv(x_train, y_train, params = parameters, model = rfr, scoring = 'neg_root_mean_squared_error', cv=3)

"""Model training using best hyper parameters"""

rfr = RandomForestRegressor(max_depth = 4, n_estimators = 500)

rfr.fit(x_train, y_train)

#prediction for train and test data

y_tr_pred_rfr = rfr.predict(x_train)

y_te_pred_rfr = rfr.predict(x_test)

"""Model evaluation"""

# compute R2 value for checking performance of model on training and test data

r2_train_rfr = metrics.r2_score(y_train, y_tr_pred_rfr)
r2_test_rfr = metrics.r2_score(y_test, y_te_pred_rfr)

rmse_train_rfr = metrics.mean_squared_error(y_train, y_tr_pred_rfr, squared = False)
rmse_test_rfr = metrics.mean_squared_error(y_test, y_te_pred_rfr, squared = False)

print('R2 score on train data :',r2_train_rfr)
print('R2 score on test data :',r2_test_rfr)
print('Root mean squared error on train data :',rmse_train_rfr)
print('Root mean squared error on test data :',rmse_test_rfr)

"""Plotting a graph"""

fig, (ax1) = plt.subplots(1, figsize=(12,6))
plt.scatter(y_test, y_te_pred_rfr)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Random Forest Regressor")
plt.show()

df.columns

"""**MODEL COMPARISON**"""

#using prettytable library we can build a table, to compare our models
x = PrettyTable()

x.field_names = ['Model', 'Parameters', 'Train_RMSE', 'Test_RMSE', 'Train_R2_Score', 'Test_R2_Score']

x.add_row(['Linear Regression', 'NA', round(rmse_train_lr, 2), round(rmse_test_lr, 2), round(r2_train_lr, 2), round(r2_test_lr, 2)])
x.add_row(['SVR Regressor', best_params_svr, round(rmse_train_svr, 2), round(rmse_test_svr,2), round(r2_train_svr, 2), round(r2_test_svr, 2)])
x.add_row(['Random Forest Regressor', best_params_rfr, round(rmse_train_rfr, 2), round(rmse_test_rfr, 2), round(r2_train_rfr, 2), round(r2_test_rfr, 2)])
print(x)

"""Among the 3 models, Random Forest Regressor seems to be the best model"""

import pickle  

pickle.dump(rfr,open('fhs_rf.pkl','wb'))